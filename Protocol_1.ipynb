{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Datasets API enables researchers to search for files in the TCGA (legacy hg19) data set based on metadata. Similar endpoints are available for querying other public datasets such as CCLE. All researchers can perform queries to return Case, Sample, and File IDs and import level 3 files (i.e., files containing non-personally identifiable information), such as gene quantification or somatic VCF files. Files containing personally identifiable data, such as germline VCF files and raw sequencing data, can only be accessed with appropriate dbGaP permissions on the CGC. In this section, we will show how to write a script using the Python bindings for the Datasets API to search for and import into projects RNA-sequencing data from matched tumor-normal samples from patients diagnosed with BRCA.  \n",
    "\n",
    "Necessary Requirements \n",
    "- A computer with internet access and an up-to-date Internet browser (e.g. Firefox, Chrome, Safari). \n",
    "- An account on the Seven Bridges’ Cancer Genomics Cloud (CGC) (https://cgc.sbgenomics.com). To access Controlled Data from TCGA, you need to register with your eRA Commons or NIH-CIT credentials and have access permissions through the Database of Genotypes and Phenotypes (dbGaP) (Link: https://dbgap.ncbi.nlm.nih.gov/aa/wga.cgi?page=login).\n",
    "- Install conda and the Python bindings for the Seven Bridges API using:\n",
    "        > pip install sevenbridges-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The Datasets API employs API requests written in JSON format to return entities such as Case, Sample, or File IDs. We will use two Python modules, json and requests, to write a wrapper around the API request, so the first step is to import these modules. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from requests import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) We define a simple function to send and receive JSONs from the API using correctly formatted HTTP calls. The token is your Authentication token - we’ll tell you how to get that in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def api_call(path, method='GET', query=None, data=None, token=None):\n",
    "    # Base URL for datasets API     \n",
    "    base_url = 'https://cgc-datasets-api.sbgenomics.com/datasets/tcga/v0/'\n",
    "    \n",
    "    # input for API call converted to json format\n",
    "    data = json.dumps(data) if isinstance(data, dict) \\\n",
    "        or isinstance(data,list) else None\n",
    "              \n",
    "    # header for API call\n",
    "    headers = {\n",
    "        'X-SBG-Auth-Token': token,\n",
    "        'Accept': 'application/json',\n",
    "        'Content-type': 'application/json',\n",
    "    }\n",
    "     \n",
    "    # API call\n",
    "    response = request(method, base_url + path, params=query, \\\n",
    "                       data=data, headers=headers)\n",
    "    #Converting response from JSON to dictionary\n",
    "    response_dict = response.json() if \\\n",
    "        response.json() else {}\n",
    " \n",
    "    if response.status_code / 100 != 2:\n",
    "        print(response_dict['message'])\n",
    "        print('Error Code: %i.' % (response_dict['code']))\n",
    "        print(response_dict['more_info'])\n",
    "        raise Exception('Server responded with status code %s.' \\\n",
    "                        % response.status_code)\n",
    "    return response_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Next obtain your CGC Authentication token for the API from the Developer Dashboard within your account. To access the Developer Dashboard, click on your username in the upper right corner and then click Developer. Click on Auth token to access the Authentication token (Figure 10). Note: Your Auth token allows access to the CGC and your projects; treat it as you would your password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_token = \"Your Authentication Token Here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Now we build a query in JSON format to find primary tumor samples that (i) are from Cases (i.e., patients) diagnosed with Breast Invasive Carcinoma and (ii)  have associated RNA-Seq reads. You can query each entity’s schema using an API call such as http://docs.cancergenomicscloud.org/docs/query-via-the-datasets-api#section-step-1-get-an-entity-s-metadata-schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tumor_samples_query = {\n",
    "    \"entity\": \"samples\",\n",
    "    \"hasSampleType\": \"Primary Tumor\",\n",
    "    \"hasCase\": {\n",
    "        \"hasDiseaseType\" : \"Breast Invasive Carcinoma\",\n",
    "        },\n",
    "    \"hasFile\": {\n",
    "        \"hasExperimentalStrategy\": \"RNA-Seq\",\n",
    "         \"hasDataFormat\" : \"TARGZ\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Next we perform an API query using the function from step 2 and the query from step 4 to return the number of BRCA primary tumor samples with RNA-seq reads files. Adding “query/total” to the base TCGA metadata path ensures that you get the number of samples that match the above metadata query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = api_call(method='POST', path ='query/total', \\\n",
    "                 token=auth_token, data=tumor_samples_query)\n",
    "print(\"There are {} samples matching the query\".format(total['total']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Next, we define a simple function to get all matches to the query using the correctly formatted HTTP calls. The previous API call gave the total number of samples related to the query (primary tumor samples from breast invasive carcinoma cases that have raw RNA-seq reads). If you want a list of IDs and all the metadata associated with the samples that match this query, we need to add just “query” to the path and get the results for all samples matching the metadata query. In addition, the results are returned in the form of pages with a maximum of 100 entities per page. Hence, we have to loop through the results to get the final list of sample IDs and associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def getAllMatches(auth_token, query_body):\n",
    "    numberFiles = api_call(method=\"POST\", path=\"query/total\", \\\n",
    "                                       token=auth_token, data=query_body)[\"total\"]\n",
    "    numCalls = int(math.ceil(numberFiles/100.0))\n",
    "    matches = []\n",
    "    entity = query_body[\"entity\"]\n",
    "    for i in range(0, numCalls):\n",
    "        query_body[\"offset\"] = str(i * 100)\n",
    "        currSet = api_call(method=\"POST\", path=\"query\" \\\n",
    "            , token=auth_token, data=query_body)[\"_embedded\"][entity]\n",
    "        for currMatch in currSet:\n",
    "            matches.append(currMatch)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) We can call this new function to return all the sample IDs that match the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tumor_samples = getAllMatches(auth_token, tumor_samples_query)\n",
    "tumor_sample_ids = [curr_sample[\"id\"] for curr_sample in tumor_samples]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) We can similarly query for normal tissue samples that are BRCA solid tissue normal samples with RNA-seq reads files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_normal_samples_query = {\n",
    "    \"entity\": \"samples\",\n",
    "    \"hasSampleType\": \"Solid Tissue Normal\",\n",
    "    \"hasCase\": {\n",
    "        \"hasDiseaseType\" : \"Breast Invasive Carcinoma\"\n",
    "        },\n",
    "    \"hasFile\": {\n",
    "        \"hasExperimentalStrategy\": \"RNA-Seq\",\n",
    "        \"hasDataFormat\" : \"TARGZ\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "tissue_normal_samples = getAllMatches(auth_token, tissue_normal_samples_query)\n",
    "tissue_normal_sample_ids = [curr_sample[\"id\"] for curr_sample in tissue_normal_samples]\n",
    "total = api_call(method='POST', path ='query/total', \\\n",
    "                 token=auth_token, data=tissue_normal_samples_query)\n",
    "print(\"There are {} samples matching the query\".format(total['total']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) To identify the corresponding Cases (patients) that have either tumor samples or tissue normal samples with RNA-seq experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tumor_cases_query = {\n",
    "    \"entity\": \"cases\",\n",
    "    \"hasSample\": tumor_sample_ids\n",
    "}\n",
    "tumor_cases = getAllMatches(auth_token, tumor_cases_query)\n",
    "tumor_case_ids = [curr_case[\"id\"] for curr_case in tumor_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tissue_normal_cases_query = {\n",
    "    \"entity\": \"cases\",\n",
    "    \"hasSample\": tissue_normal_sample_ids\n",
    "}\n",
    "tissue_normal_cases = getAllMatches(auth_token, tissue_normal_cases_query)\n",
    "tissue_normal_case_ids = [curr_case[\"id\"] for curr_case in tissue_normal_cases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) To identify the subset of patients with RNA-seq experiments for both primary tumor and tissue normal, we take the intersection of the two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_match_case_ids = list(set(tumor_case_ids) & set(tissue_normal_case_ids))\n",
    "print(\"There are {} cases that have both primary tumor and solid tissue normal samples with RNA-seq experiments\".format(len(tumor_match_case_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Now we obtain the paired tumor-normal samples by querying using the Case IDs and appropriate metadata for the primary tumor and solid tissue normal samples, respectively. We return a list of json objects corresponding to the metadata for each file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tumor_match_files_query = {\n",
    "    \"entity\": \"files\",\n",
    "    \"hasExperimentalStrategy\": \"RNA-Seq\",\n",
    "    \"hasDataFormat\" : \"TARGZ\",\n",
    "    \"hasSample\": {\n",
    "        \"hasSampleType\" : \"Primary Tumor\"\n",
    "    },\n",
    "    \"hasCase\": tumor_match_case_ids\n",
    "}\n",
    "tumor_match_files = getAllMatches(auth_token, tumor_match_files_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tissue_normal_match_files_query = {\n",
    "    \"entity\": \"files\",\n",
    "    \"hasExperimentalStrategy\": \"RNA-Seq\",\n",
    "    \"hasDataFormat\" : \"TARGZ\",\n",
    "    \"hasSample\": {\n",
    "        \"hasSampleType\" : \"Solid Tissue Normal\"\n",
    "    },\n",
    "    \"hasCase\": tumor_match_case_ids\n",
    "}\n",
    "tissue_normal_match_files = getAllMatches(auth_token, tissue_normal_match_files_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"There are {} files corresponding to raw reads for Tumor samples in tumor-normal matched cases for BRCA\".format(len(tumor_match_files)))\n",
    "print(\"There are {} files corresponding to raw reads for Solid tissue normal samples in tumor-normal matched cases for BRCA\".format(len(tissue_normal_match_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) The File objects associate information with the File ID (a unique identifier for a file on the CGC), and this ID can be used to copy the file your project. In the case of Controlled Access data, you must have appropriate dbGaP permissions to copy these files or view their contents. Now you can initialize the Seven Bridges python bindings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sevenbridges as sbg\n",
    "api = sbg.Api(url='https://cgc-api.sbgenomics.com/v2', token=auth_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) If you haven’t already made a project for these files using the GUI, you can create one using the API. To create a new project, you need to provide a project name and a billing group. This code block selects the first billing group available, which will return a user’s personal billing group in most cases. If you are involved in collaborations and are in multiple billing groups, you will want to select the appropriate one for each project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_project_name = 'Protocol 1'                          \n",
    "billing_groups = api.billing_groups.query()  \n",
    "print((billing_groups[0].name + \\\n",
    "       ' will be charged for computation and storage (if applicable) for your new project'))\n",
    "\n",
    "new_project = {\n",
    "        'billing_group': billing_groups[0].id,\n",
    "        'name': new_project_name, \n",
    "        'tags': ['tcga']\n",
    "}\n",
    "\n",
    "my_project = api.projects.create(name = new_project['name'], \\\n",
    "                                 billing_group = new_project['billing_group'], \\\n",
    "                                 tags = new_project['tags'])\n",
    "my_project = [p for p in api.projects.query(limit=100).all() \\\n",
    "              if p.name == new_project_name][0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Now you can copy the files to the project. The ID of each file returned from the Datasets API can be used to copy each file onto a project on the user’s workspace. To do this, we create a function that loops through the list of files we want to copy and copies each file to the user’s project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_project(api, my_project, final_files):\n",
    "    new_files = []\n",
    "    for curr_file in final_files:\n",
    "        file_object = api.files.get(id = curr_file['id'])\n",
    "        my_new_file = file_object.copy(project = my_project.id, name = file_object.name)\n",
    "        new_files.append(my_new_file)\n",
    "    print(\"Files Imported!\")\n",
    "\n",
    "\n",
    "copy_to_project(api, my_project, tumor_match_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
